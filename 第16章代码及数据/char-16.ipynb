{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.3 实例：使用Estimator预定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这节我们用Estimator的预定义模型来解决手写10个数字问题，数据集为MNIST。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1）下载并读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#读取数据，为避免网络问题，可以先将数据下载到当前MNIST_data目录下\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=False)\n",
    "\n",
    "# 定义训练使用的输入特征列。\n",
    "feature_columns = [tf.feature_column.numeric_column(\"image\", shape=[784])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）实例化Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_dir', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# 创建两个隐含层,节点数分别为200、50\n",
    "estimator = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                       hidden_units=[200,50],                                      \n",
    "                                       optimizer=tf.train.AdamOptimizer(1e-4),\n",
    "                                       n_classes=10,\n",
    "                                       dropout=0.2,\n",
    "                                       model_dir=\"model_dir\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into model_dir/model.ckpt.\n",
      "INFO:tensorflow:loss = 302.131, step = 1\n",
      "INFO:tensorflow:global_step/sec: 76.0175\n",
      "INFO:tensorflow:loss = 192.091, step = 101 (1.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.452\n",
      "INFO:tensorflow:loss = 120.149, step = 201 (1.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.384\n",
      "INFO:tensorflow:loss = 100.273, step = 301 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1762\n",
      "INFO:tensorflow:loss = 98.3329, step = 401 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.919\n",
      "INFO:tensorflow:loss = 66.3525, step = 501 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1972\n",
      "INFO:tensorflow:loss = 55.7102, step = 601 (1.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.764\n",
      "INFO:tensorflow:loss = 56.7284, step = 701 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.117\n",
      "INFO:tensorflow:loss = 71.3866, step = 801 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3708\n",
      "INFO:tensorflow:loss = 67.4666, step = 901 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.12\n",
      "INFO:tensorflow:loss = 58.6684, step = 1001 (1.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1406\n",
      "INFO:tensorflow:loss = 51.2913, step = 1101 (1.296 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3779\n",
      "INFO:tensorflow:loss = 53.5094, step = 1201 (1.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8624\n",
      "INFO:tensorflow:loss = 27.3626, step = 1301 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4156\n",
      "INFO:tensorflow:loss = 40.3245, step = 1401 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9233\n",
      "INFO:tensorflow:loss = 45.5067, step = 1501 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9422\n",
      "INFO:tensorflow:loss = 42.7841, step = 1601 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8176\n",
      "INFO:tensorflow:loss = 40.5156, step = 1701 (1.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2954\n",
      "INFO:tensorflow:loss = 42.9128, step = 1801 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.4193\n",
      "INFO:tensorflow:loss = 26.915, step = 1901 (1.341 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0954\n",
      "INFO:tensorflow:loss = 37.3266, step = 2001 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.295\n",
      "INFO:tensorflow:loss = 42.2662, step = 2101 (1.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.5592\n",
      "INFO:tensorflow:loss = 30.9235, step = 2201 (1.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.6228\n",
      "INFO:tensorflow:loss = 25.3113, step = 2301 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4415\n",
      "INFO:tensorflow:loss = 27.7411, step = 2401 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5717\n",
      "INFO:tensorflow:loss = 49.5455, step = 2501 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3313\n",
      "INFO:tensorflow:loss = 49.8113, step = 2601 (1.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1115\n",
      "INFO:tensorflow:loss = 32.2658, step = 2701 (1.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.141\n",
      "INFO:tensorflow:loss = 41.5802, step = 2801 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4282\n",
      "INFO:tensorflow:loss = 31.1548, step = 2901 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.748\n",
      "INFO:tensorflow:loss = 19.5539, step = 3001 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.1996\n",
      "INFO:tensorflow:loss = 22.5722, step = 3101 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9229\n",
      "INFO:tensorflow:loss = 22.6469, step = 3201 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8424\n",
      "INFO:tensorflow:loss = 38.4047, step = 3301 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9138\n",
      "INFO:tensorflow:loss = 34.8234, step = 3401 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4398\n",
      "INFO:tensorflow:loss = 23.5166, step = 3501 (1.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0687\n",
      "INFO:tensorflow:loss = 23.9106, step = 3601 (1.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6526\n",
      "INFO:tensorflow:loss = 17.3123, step = 3701 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7384\n",
      "INFO:tensorflow:loss = 36.0318, step = 3801 (1.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1115\n",
      "INFO:tensorflow:loss = 42.5049, step = 3901 (1.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0521\n",
      "INFO:tensorflow:loss = 24.5719, step = 4001 (1.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9151\n",
      "INFO:tensorflow:loss = 18.5948, step = 4101 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5939\n",
      "INFO:tensorflow:loss = 35.3609, step = 4201 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.4447\n",
      "INFO:tensorflow:loss = 51.5615, step = 4301 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2994\n",
      "INFO:tensorflow:loss = 20.0017, step = 4401 (1.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.13\n",
      "INFO:tensorflow:loss = 22.3971, step = 4501 (1.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.1964\n",
      "INFO:tensorflow:loss = 9.69357, step = 4601 (1.348 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4072\n",
      "INFO:tensorflow:loss = 26.187, step = 4701 (1.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1808\n",
      "INFO:tensorflow:loss = 14.1712, step = 4801 (1.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.0476\n",
      "INFO:tensorflow:loss = 26.507, step = 4901 (1.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4792\n",
      "INFO:tensorflow:loss = 18.1221, step = 5001 (1.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8443\n",
      "INFO:tensorflow:loss = 25.5397, step = 5101 (1.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6654\n",
      "INFO:tensorflow:loss = 22.6643, step = 5201 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1093\n",
      "INFO:tensorflow:loss = 27.971, step = 5301 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.889\n",
      "INFO:tensorflow:loss = 23.8548, step = 5401 (1.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8908\n",
      "INFO:tensorflow:loss = 18.5722, step = 5501 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0847\n",
      "INFO:tensorflow:loss = 18.2062, step = 5601 (1.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9862\n",
      "INFO:tensorflow:loss = 25.4237, step = 5701 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.2561\n",
      "INFO:tensorflow:loss = 16.6635, step = 5801 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9709\n",
      "INFO:tensorflow:loss = 12.639, step = 5901 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4085\n",
      "INFO:tensorflow:loss = 21.7178, step = 6001 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9635\n",
      "INFO:tensorflow:loss = 20.6793, step = 6101 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.5989\n",
      "INFO:tensorflow:loss = 17.2709, step = 6201 (1.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5285\n",
      "INFO:tensorflow:loss = 16.9423, step = 6301 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8082\n",
      "INFO:tensorflow:loss = 10.1418, step = 6401 (1.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4455\n",
      "INFO:tensorflow:loss = 12.5892, step = 6501 (1.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4593\n",
      "INFO:tensorflow:loss = 26.8368, step = 6601 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.6027\n",
      "INFO:tensorflow:loss = 8.76348, step = 6701 (1.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0358\n",
      "INFO:tensorflow:loss = 22.0948, step = 6801 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0169\n",
      "INFO:tensorflow:loss = 20.5751, step = 6901 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4556\n",
      "INFO:tensorflow:loss = 6.10272, step = 7001 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.862\n",
      "INFO:tensorflow:loss = 16.2042, step = 7101 (1.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.602\n",
      "INFO:tensorflow:loss = 23.5588, step = 7201 (1.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8267\n",
      "INFO:tensorflow:loss = 17.6729, step = 7301 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5092\n",
      "INFO:tensorflow:loss = 18.4746, step = 7401 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4281\n",
      "INFO:tensorflow:loss = 29.5996, step = 7501 (1.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.8298\n",
      "INFO:tensorflow:loss = 12.383, step = 7601 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6636\n",
      "INFO:tensorflow:loss = 22.0949, step = 7701 (1.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4762\n",
      "INFO:tensorflow:loss = 18.773, step = 7801 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7833\n",
      "INFO:tensorflow:loss = 25.6236, step = 7901 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.828\n",
      "INFO:tensorflow:loss = 7.80016, step = 8001 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5564\n",
      "INFO:tensorflow:loss = 12.3424, step = 8101 (1.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9235\n",
      "INFO:tensorflow:loss = 14.1939, step = 8201 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5672\n",
      "INFO:tensorflow:loss = 17.1979, step = 8301 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4619\n",
      "INFO:tensorflow:loss = 21.019, step = 8401 (1.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8519\n",
      "INFO:tensorflow:loss = 9.84585, step = 8501 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3519\n",
      "INFO:tensorflow:loss = 27.061, step = 8601 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.823\n",
      "INFO:tensorflow:loss = 15.4803, step = 8701 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9641\n",
      "INFO:tensorflow:loss = 21.4167, step = 8801 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.6211\n",
      "INFO:tensorflow:loss = 9.31094, step = 8901 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1654\n",
      "INFO:tensorflow:loss = 31.2943, step = 9001 (1.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1255\n",
      "INFO:tensorflow:loss = 7.44898, step = 9101 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3891\n",
      "INFO:tensorflow:loss = 11.1459, step = 9201 (1.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6017\n",
      "INFO:tensorflow:loss = 9.33223, step = 9301 (1.322 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6922\n",
      "INFO:tensorflow:loss = 19.7163, step = 9401 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9739\n",
      "INFO:tensorflow:loss = 11.0901, step = 9501 (1.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1425\n",
      "INFO:tensorflow:loss = 10.9156, step = 9601 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2626\n",
      "INFO:tensorflow:loss = 12.0057, step = 9701 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9661\n",
      "INFO:tensorflow:loss = 12.7632, step = 9801 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7889\n",
      "INFO:tensorflow:loss = 9.58842, step = 9901 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2683\n",
      "INFO:tensorflow:loss = 23.9298, step = 10001 (1.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.1598\n",
      "INFO:tensorflow:loss = 12.761, step = 10101 (1.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8696\n",
      "INFO:tensorflow:loss = 23.4676, step = 10201 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9165\n",
      "INFO:tensorflow:loss = 18.0485, step = 10301 (1.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3013\n",
      "INFO:tensorflow:loss = 10.8404, step = 10401 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7235\n",
      "INFO:tensorflow:loss = 10.3162, step = 10501 (1.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7025\n",
      "INFO:tensorflow:loss = 13.5858, step = 10601 (1.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8828\n",
      "INFO:tensorflow:loss = 20.4597, step = 10701 (1.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3479\n",
      "INFO:tensorflow:loss = 15.2896, step = 10801 (1.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2065\n",
      "INFO:tensorflow:loss = 13.6097, step = 10901 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7639\n",
      "INFO:tensorflow:loss = 5.94358, step = 11001 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3093\n",
      "INFO:tensorflow:loss = 7.02537, step = 11101 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0974\n",
      "INFO:tensorflow:loss = 9.68375, step = 11201 (1.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1323\n",
      "INFO:tensorflow:loss = 14.1035, step = 11301 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3333\n",
      "INFO:tensorflow:loss = 11.8509, step = 11401 (1.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0287\n",
      "INFO:tensorflow:loss = 9.44987, step = 11501 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4717\n",
      "INFO:tensorflow:loss = 14.7876, step = 11601 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.7832\n",
      "INFO:tensorflow:loss = 9.28846, step = 11701 (1.223 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4523\n",
      "INFO:tensorflow:loss = 10.4369, step = 11801 (1.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9755\n",
      "INFO:tensorflow:loss = 15.7696, step = 11901 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.8757\n",
      "INFO:tensorflow:loss = 13.0352, step = 12001 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.3787\n",
      "INFO:tensorflow:loss = 8.26259, step = 12101 (1.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7227\n",
      "INFO:tensorflow:loss = 16.3826, step = 12201 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2429\n",
      "INFO:tensorflow:loss = 7.04211, step = 12301 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9381\n",
      "INFO:tensorflow:loss = 9.89336, step = 12401 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.4872\n",
      "INFO:tensorflow:loss = 12.6758, step = 12501 (1.328 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2119\n",
      "INFO:tensorflow:loss = 5.19525, step = 12601 (1.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.4357\n",
      "INFO:tensorflow:loss = 9.10747, step = 12701 (1.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.6502\n",
      "INFO:tensorflow:loss = 16.7195, step = 12801 (1.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.6495\n",
      "INFO:tensorflow:loss = 12.6021, step = 12901 (1.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2333\n",
      "INFO:tensorflow:loss = 5.64484, step = 13001 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.2489\n",
      "INFO:tensorflow:loss = 8.29033, step = 13101 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9223\n",
      "INFO:tensorflow:loss = 16.1835, step = 13201 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.2224\n",
      "INFO:tensorflow:loss = 11.4634, step = 13301 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5342\n",
      "INFO:tensorflow:loss = 10.558, step = 13401 (1.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.3598\n",
      "INFO:tensorflow:loss = 29.5665, step = 13501 (1.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.007\n",
      "INFO:tensorflow:loss = 6.23472, step = 13601 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.0787\n",
      "INFO:tensorflow:loss = 13.8801, step = 13701 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.272\n",
      "INFO:tensorflow:loss = 7.47121, step = 13801 (1.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.4386\n",
      "INFO:tensorflow:loss = 10.012, step = 13901 (1.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8072\n",
      "INFO:tensorflow:loss = 3.20478, step = 14001 (1.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.7511\n",
      "INFO:tensorflow:loss = 7.21188, step = 14101 (1.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8815\n",
      "INFO:tensorflow:loss = 6.81645, step = 14201 (1.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.4439\n",
      "INFO:tensorflow:loss = 5.31655, step = 14301 (1.326 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9052\n",
      "INFO:tensorflow:loss = 4.58652, step = 14401 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8458\n",
      "INFO:tensorflow:loss = 9.45308, step = 14501 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0733\n",
      "INFO:tensorflow:loss = 5.00089, step = 14601 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.0103\n",
      "INFO:tensorflow:loss = 5.65976, step = 14701 (1.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0289\n",
      "INFO:tensorflow:loss = 9.38832, step = 14801 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1239\n",
      "INFO:tensorflow:loss = 17.6494, step = 14901 (1.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6409\n",
      "INFO:tensorflow:loss = 3.59485, step = 15001 (1.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.4347\n",
      "INFO:tensorflow:loss = 12.9702, step = 15101 (1.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6599\n",
      "INFO:tensorflow:loss = 21.906, step = 15201 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3146\n",
      "INFO:tensorflow:loss = 7.82264, step = 15301 (1.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3158\n",
      "INFO:tensorflow:loss = 12.94, step = 15401 (1.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.887\n",
      "INFO:tensorflow:loss = 5.30341, step = 15501 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.6864\n",
      "INFO:tensorflow:loss = 6.67121, step = 15601 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4856\n",
      "INFO:tensorflow:loss = 11.998, step = 15701 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.7549\n",
      "INFO:tensorflow:loss = 6.82452, step = 15801 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2627\n",
      "INFO:tensorflow:loss = 8.65432, step = 15901 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.042\n",
      "INFO:tensorflow:loss = 9.31604, step = 16001 (1.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3269\n",
      "INFO:tensorflow:loss = 13.2297, step = 16101 (1.294 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.937\n",
      "INFO:tensorflow:loss = 7.74257, step = 16201 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.041\n",
      "INFO:tensorflow:loss = 5.46169, step = 16301 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.5895\n",
      "INFO:tensorflow:loss = 10.4913, step = 16401 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.889\n",
      "INFO:tensorflow:loss = 18.0658, step = 16501 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9053\n",
      "INFO:tensorflow:loss = 13.6253, step = 16601 (1.216 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9609\n",
      "INFO:tensorflow:loss = 15.0025, step = 16701 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1934\n",
      "INFO:tensorflow:loss = 19.4625, step = 16801 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8564\n",
      "INFO:tensorflow:loss = 13.4828, step = 16901 (1.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.706\n",
      "INFO:tensorflow:loss = 7.96829, step = 17001 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3532\n",
      "INFO:tensorflow:loss = 10.9218, step = 17101 (1.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2335\n",
      "INFO:tensorflow:loss = 13.2078, step = 17201 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3134\n",
      "INFO:tensorflow:loss = 11.4933, step = 17301 (1.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.2609\n",
      "INFO:tensorflow:loss = 3.72299, step = 17401 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4504\n",
      "INFO:tensorflow:loss = 7.26136, step = 17501 (1.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.3279\n",
      "INFO:tensorflow:loss = 6.91, step = 17601 (1.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0902\n",
      "INFO:tensorflow:loss = 21.4797, step = 17701 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.5478\n",
      "INFO:tensorflow:loss = 7.37789, step = 17801 (1.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.2487\n",
      "INFO:tensorflow:loss = 4.17905, step = 17901 (1.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0677\n",
      "INFO:tensorflow:loss = 5.03311, step = 18001 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1325\n",
      "INFO:tensorflow:loss = 6.20908, step = 18101 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.554\n",
      "INFO:tensorflow:loss = 6.09861, step = 18201 (1.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6703\n",
      "INFO:tensorflow:loss = 1.9098, step = 18301 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8746\n",
      "INFO:tensorflow:loss = 11.2482, step = 18401 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.4958\n",
      "INFO:tensorflow:loss = 5.90016, step = 18501 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.873\n",
      "INFO:tensorflow:loss = 9.90852, step = 18601 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.1125\n",
      "INFO:tensorflow:loss = 5.70946, step = 18701 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3774\n",
      "INFO:tensorflow:loss = 5.92802, step = 18801 (1.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.841\n",
      "INFO:tensorflow:loss = 15.4447, step = 18901 (1.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.9249\n",
      "INFO:tensorflow:loss = 9.80873, step = 19001 (1.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2565\n",
      "INFO:tensorflow:loss = 12.0805, step = 19101 (1.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8686\n",
      "INFO:tensorflow:loss = 6.93198, step = 19201 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.3289\n",
      "INFO:tensorflow:loss = 11.5589, step = 19301 (1.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.4606\n",
      "INFO:tensorflow:loss = 7.04607, step = 19401 (1.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.5248\n",
      "INFO:tensorflow:loss = 3.7116, step = 19501 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7296\n",
      "INFO:tensorflow:loss = 4.73804, step = 19601 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.4678\n",
      "INFO:tensorflow:loss = 3.69993, step = 19701 (1.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.401\n",
      "INFO:tensorflow:loss = 11.8448, step = 19801 (1.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.1497\n",
      "INFO:tensorflow:loss = 9.83897, step = 19901 (1.369 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into model_dir/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.45521.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fb510f29240>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      num_epochs=None,\n",
    "      batch_size=128,\n",
    "      shuffle=True)\n",
    "\n",
    "estimator.train(input_fn=train_input_fn, steps=20000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（4）测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-06-27-03:37:02\n",
      "INFO:tensorflow:Restoring parameters from model_dir/model.ckpt-20000\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-27-03:37:03\n",
      "INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9788, average_loss = 0.06891, global_step = 20000, loss = 8.72279\n",
      "\n",
      "Test Accuracy: 0.9788\n",
      "\n",
      "{'accuracy': 0.9788, 'average_loss': 0.06891001, 'loss': 8.7227859, 'global_step': 20000}\n"
     ]
    }
   ],
   "source": [
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"image\": mnist.test.images},\n",
    "      y=mnist.test.labels.astype(np.int32),\n",
    "      num_epochs=1,\n",
    "      batch_size=128,\n",
    "      shuffle=False)\n",
    "\n",
    "test_results = estimator.evaluate(input_fn=test_input_fn)\n",
    "accuracy_score = test_results[\"accuracy\"]\n",
    "print(\"\\nTest Accuracy: {0:.4f}\\n\".format(accuracy_score))\n",
    "\n",
    "print(test_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程序非常简洁，精度达98%左右，应该还不错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.4 实例：使用Estimator自定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）导入一些库及定义几个变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using model dir: ./custom_model_dir/1530070694\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "DATA_DIR = './MNIST_data/'\n",
    "MODEL_DIR = os.path.join(\"./custom_model_dir\",str(int(time.time())))\n",
    "\n",
    "NUM_STEPS = 1000\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "print(\"using model dir: %s\" % MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）定义模型函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"定义模型函数\"\"\"\n",
    "\n",
    "  # 输入层\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  # MNIST图片是 28x28像素, 有一个彩色通道\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  #卷积层1\n",
    "  # 32个大小为 5x5的卷积核，ReLU为激活函数。\n",
    "  # 填充格式为same\n",
    "  # 输入张量形状: [batch_size, 28, 28, 1]\n",
    "  # 输出张量形状: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  conv1= tf.layers.batch_normalization(inputs=conv1, training=mode == tf.estimator.ModeKeys.TRAIN, name='BN1')\n",
    " # 池化层1\n",
    "# 使用 2x2 大小卷积核 ，步幅为2\n",
    "  # 输入张量形状: [batch_size, 28, 28, 32]\n",
    "  # 输出张量形状: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # 卷积层2\n",
    "  # 64个大小为 5x5的卷积核\n",
    "  # 填充格式为same\n",
    "  #输入张量形状: [batch_size, 14, 14, 32]\n",
    "  #输出张量形状: [batch_size, 14, 14, 64]\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  #池化层2\n",
    "  # 最大池化层使用大小为 2x2卷积核，步幅为 2\n",
    "  #输入张量形状: [batch_size, 14, 14, 64]\n",
    "  #输出张量形状: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # 把张量展平为向量\n",
    "  #输入张量形状: [batch_size, 7, 7, 64]\n",
    "  #输出张量形状: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # 全连接层\n",
    "  # 全连接层共有 1024神经元\n",
    "  #输入张量形状: [batch_size, 7 * 7 * 64]\n",
    "  #输出张量形状: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu, name=\"dense1\")\n",
    "\n",
    "  # 增加一个dropout操作，保持神经元比率为0.6\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # 逻辑层\n",
    "  #输入张量形状: [batch_size, 1024]\n",
    "  #输出张量形状: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # 产生预测值\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # 把`softmax_tensor` 添加到数据流图中，被用来记录相关日志\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  prediction_output = tf.estimator.export.PredictOutput({\"classes\": tf.argmax(input=logits, axis=1),\n",
    "     \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")})\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions,\n",
    "        export_outputs={tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_output})\n",
    "\n",
    "  # 计算代价函数\n",
    "  onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "  loss = tf.losses.softmax_cross_entropy(\n",
    "      onehot_labels=onehot_labels, logits=logits)\n",
    "  # Generate some summary info\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  tf.summary.histogram('conv1', conv1)\n",
    "  tf.summary.histogram('dense', dense)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # 添加评估指标\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)定义读取训练数据的输入函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_input_fn(dataset, batch_size=BATCH_SIZE):\n",
    "    def _input_fn():\n",
    "        X = tf.constant(dataset.images)\n",
    "        Y = tf.constant(dataset.labels, dtype=tf.int32)\n",
    "        image_batch, label_batch = tf.train.shuffle_batch([X,Y],\n",
    "                               batch_size=batch_size,\n",
    "                               capacity=8*batch_size,\n",
    "                               min_after_dequeue=4*batch_size,\n",
    "                               enqueue_many=True\n",
    "                              )\n",
    "        return {'x': image_batch} , label_batch\n",
    "\n",
    "    return _input_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（5）加载训练数据及预测数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "#加载训练和评估数据\n",
    "\n",
    "mnist = input_data.read_data_sets(DATA_DIR)\n",
    "train_data = mnist.train.images  # Returns np.array\n",
    "train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "\n",
    "eval_data = mnist.test.images  # Returns np.array\n",
    "eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "predict_data_batch = mnist.test.next_batch(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（6）创建Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './custom_model_dir/1530070694', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "#创建Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=MODEL_DIR)\n",
    "\n",
    "# 设置预测日志\n",
    "# 记录预测值\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=2000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（7）训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./custom_model_dir/1530070694/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[ 0.17813101  0.04493942  0.02448348  0.0664119   0.08420388  0.064909\n",
      "   0.05033232  0.15677786  0.17856245  0.15124871]\n",
      " [ 0.11374522  0.0033673   0.04355712  0.05594146  0.35690925  0.18629949\n",
      "   0.06725534  0.0182317   0.12132526  0.03336786]\n",
      " [ 0.27906948  0.0629778   0.01588251  0.01982711  0.08707919  0.10208602\n",
      "   0.00684219  0.01165158  0.02791901  0.38666514]\n",
      " [ 0.44308415  0.04374738  0.01804689  0.02070023  0.08784977  0.03303255\n",
      "   0.0282712   0.01923699  0.23889402  0.06713685]\n",
      " [ 0.06094289  0.02937726  0.01713669  0.04297196  0.20445527  0.03170442\n",
      "   0.01256318  0.0356194   0.23273905  0.33248985]\n",
      " [ 0.24763039  0.20830308  0.1309119   0.03167938  0.09013233  0.07625874\n",
      "   0.03084239  0.10888833  0.02563771  0.04971572]\n",
      " [ 0.22500195  0.01087402  0.07220987  0.07720312  0.0301585   0.07186558\n",
      "   0.1597646   0.06112551  0.06814437  0.22365248]\n",
      " [ 0.15817957  0.02354319  0.0453418   0.01467882  0.01815846  0.17466912\n",
      "   0.00977167  0.10201389  0.27769798  0.17594554]\n",
      " [ 0.03685     0.01591142  0.06798454  0.02673325  0.0453135   0.11291524\n",
      "   0.00848413  0.02847784  0.1537123   0.50361788]\n",
      " [ 0.15270232  0.03078592  0.04533033  0.06528747  0.07660016  0.15270142\n",
      "   0.22940454  0.13419886  0.04353568  0.06945332]\n",
      " [ 0.74820745  0.0127157   0.01420545  0.00929948  0.01952734  0.02696088\n",
      "   0.00351383  0.05403284  0.08802554  0.02351145]\n",
      " [ 0.18234946  0.03912064  0.05001482  0.03033774  0.16503729  0.12764901\n",
      "   0.0157616   0.0584035   0.05287743  0.27844843]\n",
      " [ 0.11985475  0.03601773  0.02087349  0.20191981  0.08492284  0.13400763\n",
      "   0.02437483  0.09654613  0.21708453  0.06439828]\n",
      " [ 0.16491626  0.05570957  0.07103376  0.1017759   0.04409059  0.05351288\n",
      "   0.00809826  0.16792627  0.09785599  0.23508048]\n",
      " [ 0.10763495  0.02110058  0.12102386  0.08282223  0.04106666  0.02241407\n",
      "   0.04480087  0.27394485  0.04852125  0.23667067]\n",
      " [ 0.07356757  0.12358353  0.03202849  0.09627496  0.0434405   0.02732715\n",
      "   0.02978225  0.05506548  0.29658693  0.22234321]\n",
      " [ 0.61475068  0.02534399  0.01708761  0.04520369  0.0182943   0.06763488\n",
      "   0.01135846  0.06751602  0.08700719  0.0458032 ]\n",
      " [ 0.22648534  0.05193642  0.01202028  0.05843957  0.06273367  0.37497804\n",
      "   0.02910055  0.07599941  0.07311305  0.03519372]\n",
      " [ 0.21652693  0.04344628  0.0275902   0.15521765  0.10014629  0.1147074\n",
      "   0.09431281  0.09682786  0.09891313  0.0523115 ]\n",
      " [ 0.14550917  0.00385992  0.01082165  0.04076806  0.01238329  0.1076378\n",
      "   0.0134248   0.0242772   0.03763304  0.60368514]\n",
      " [ 0.24986334  0.01047633  0.04071031  0.07349173  0.05121728  0.06990999\n",
      "   0.01218765  0.0192002   0.04448499  0.42845827]\n",
      " [ 0.13343635  0.01869503  0.05253732  0.2972669   0.11924903  0.07883146\n",
      "   0.00333648  0.05840912  0.19536231  0.04287594]\n",
      " [ 0.33427951  0.05433631  0.04806752  0.00607599  0.03420079  0.07954485\n",
      "   0.11934745  0.06195584  0.07264218  0.18954948]\n",
      " [ 0.09390834  0.10683607  0.01833267  0.08963007  0.02210231  0.15296638\n",
      "   0.20037584  0.02539166  0.12303875  0.16741784]\n",
      " [ 0.40437713  0.02770791  0.0467168   0.01856255  0.10258918  0.02332142\n",
      "   0.05055143  0.01479963  0.080939    0.23043489]\n",
      " [ 0.29062846  0.07136519  0.04888739  0.06478461  0.11085729  0.01714451\n",
      "   0.01156539  0.03711445  0.16226716  0.18538553]\n",
      " [ 0.25256154  0.06119802  0.05400639  0.06012109  0.03520525  0.01106358\n",
      "   0.03046     0.05745928  0.07709326  0.36083159]\n",
      " [ 0.11376944  0.03363729  0.01904781  0.0325141   0.16974089  0.11541767\n",
      "   0.03745043  0.05550297  0.08195392  0.34096551]\n",
      " [ 0.26368743  0.04940525  0.0781204   0.05484562  0.15794373  0.13541633\n",
      "   0.07812182  0.05420096  0.03620682  0.09205167]\n",
      " [ 0.18344875  0.02742882  0.15921298  0.05228032  0.03922259  0.04925533\n",
      "   0.02501056  0.09378491  0.10234615  0.26800963]\n",
      " [ 0.05525384  0.04138663  0.05817363  0.37775907  0.1126925   0.01381953\n",
      "   0.0071518   0.03744064  0.14317329  0.15314905]\n",
      " [ 0.21756724  0.03819233  0.1016303   0.00925416  0.07370313  0.28761336\n",
      "   0.04206224  0.12013214  0.05332337  0.05652168]\n",
      " [ 0.09771959  0.04836124  0.06520549  0.09848354  0.06845509  0.04553183\n",
      "   0.04489911  0.20452572  0.10861384  0.21820453]\n",
      " [ 0.18905666  0.04525556  0.04347943  0.05652811  0.07169643  0.11717334\n",
      "   0.07016055  0.04486117  0.14450008  0.21728876]\n",
      " [ 0.12530999  0.13471889  0.02348163  0.03095573  0.07994317  0.05173549\n",
      "   0.06363504  0.09189507  0.10571113  0.29261386]\n",
      " [ 0.16560234  0.07760026  0.0622622   0.03799516  0.03611734  0.21990345\n",
      "   0.03419136  0.12764929  0.19521752  0.04346106]\n",
      " [ 0.33675545  0.01489424  0.1446441   0.02836077  0.07847101  0.05305922\n",
      "   0.03165929  0.08861335  0.07354384  0.14999865]\n",
      " [ 0.07395219  0.0720899   0.05635752  0.08176013  0.15544893  0.02123944\n",
      "   0.07364363  0.25279915  0.09568445  0.11702462]\n",
      " [ 0.43748948  0.00745458  0.09398694  0.03780157  0.08144272  0.0745455\n",
      "   0.02489565  0.01051336  0.06093328  0.17093688]\n",
      " [ 0.12545963  0.06681606  0.02650625  0.12708089  0.03618827  0.08576417\n",
      "   0.01077893  0.18149623  0.08927432  0.25063527]\n",
      " [ 0.18130024  0.02734248  0.15609553  0.05705399  0.06708654  0.05411606\n",
      "   0.05580847  0.07649928  0.07086826  0.25382918]\n",
      " [ 0.08040512  0.01382775  0.09313896  0.01291126  0.05533246  0.33167344\n",
      "   0.02702379  0.18704304  0.14822969  0.05041449]\n",
      " [ 0.22720645  0.10835058  0.02774707  0.02233778  0.07841497  0.05696539\n",
      "   0.04147758  0.09127489  0.25968388  0.08654137]\n",
      " [ 0.43732733  0.00916101  0.05353015  0.02937653  0.04195136  0.02946246\n",
      "   0.02080479  0.02370345  0.23233332  0.12234958]\n",
      " [ 0.0846334   0.02494197  0.01480674  0.04019014  0.01592497  0.05805426\n",
      "   0.03544898  0.01273321  0.39556107  0.31770527]\n",
      " [ 0.03925643  0.0424361   0.10404786  0.08815447  0.0441481   0.10563172\n",
      "   0.00895318  0.03585542  0.42388484  0.10763188]\n",
      " [ 0.08267587  0.02456916  0.0102558   0.23371363  0.07460678  0.14036967\n",
      "   0.02822405  0.2473563   0.06535453  0.09287418]\n",
      " [ 0.23624441  0.02742142  0.09993002  0.11965087  0.02917424  0.1426347\n",
      "   0.01342788  0.16836047  0.12543947  0.03771657]\n",
      " [ 0.25627592  0.00572762  0.03349466  0.01376779  0.02993148  0.13659716\n",
      "   0.03410513  0.2128095   0.07990795  0.19738278]\n",
      " [ 0.06243438  0.19807014  0.04041139  0.02709859  0.02947171  0.02053144\n",
      "   0.06652177  0.10626503  0.32691196  0.12228361]\n",
      " [ 0.08536226  0.04182314  0.06635763  0.01724526  0.01873977  0.03110693\n",
      "   0.12180569  0.00833139  0.42453751  0.18469046]\n",
      " [ 0.40342268  0.0231414   0.07800728  0.10668136  0.01787721  0.11358298\n",
      "   0.02226318  0.08181453  0.07172538  0.08148401]\n",
      " [ 0.18071686  0.0201565   0.14602007  0.12804142  0.15921217  0.10231674\n",
      "   0.03893102  0.03326955  0.01761003  0.17372571]\n",
      " [ 0.36980361  0.00546277  0.33594638  0.05751842  0.03384961  0.02565394\n",
      "   0.05616228  0.05009177  0.02296128  0.04254997]\n",
      " [ 0.22021659  0.00778771  0.10838795  0.01000662  0.03844774  0.04956693\n",
      "   0.0118936   0.0722377   0.02178034  0.45967495]\n",
      " [ 0.22889207  0.05830993  0.0484911   0.01346726  0.12137367  0.16004363\n",
      "   0.12165952  0.0633687   0.11195513  0.07243904]\n",
      " [ 0.41792345  0.02533874  0.14858858  0.0505016   0.01888631  0.1321685\n",
      "   0.02454243  0.03811372  0.055703    0.08823371]\n",
      " [ 0.10337667  0.05765499  0.23548459  0.01751955  0.14866731  0.08055446\n",
      "   0.02995116  0.08419449  0.07534224  0.16725461]\n",
      " [ 0.44612473  0.03011348  0.02978079  0.06934064  0.09901333  0.06251218\n",
      "   0.02919394  0.0463197   0.0578151   0.12978612]\n",
      " [ 0.20620602  0.0369039   0.00632132  0.11704835  0.01035799  0.12877814\n",
      "   0.01264827  0.05564108  0.03890233  0.38719258]\n",
      " [ 0.06649747  0.11195204  0.04684252  0.02419424  0.139851    0.02203551\n",
      "   0.01470121  0.16530249  0.11283915  0.29578441]\n",
      " [ 0.37874919  0.04809516  0.01915647  0.04614962  0.10531852  0.107244\n",
      "   0.02106294  0.03972539  0.05496499  0.17953371]\n",
      " [ 0.39962608  0.0125999   0.0213976   0.10625916  0.03579421  0.0793473\n",
      "   0.1472546   0.01199749  0.10264318  0.08308036]\n",
      " [ 0.24335165  0.06268435  0.00934452  0.08219688  0.09287295  0.15552439\n",
      "   0.04819198  0.07427202  0.11610801  0.11545325]\n",
      " [ 0.3616758   0.04817488  0.03329884  0.05850349  0.03962121  0.07515111\n",
      "   0.10402034  0.07935821  0.17353129  0.02666486]\n",
      " [ 0.20306768  0.02616429  0.1344686   0.09813171  0.05744072  0.1003902\n",
      "   0.03687831  0.10471623  0.08022646  0.1585158 ]\n",
      " [ 0.08060332  0.18161228  0.06738283  0.01734387  0.01860046  0.03426483\n",
      "   0.02804273  0.04462258  0.26667511  0.26085201]\n",
      " [ 0.10430582  0.00965243  0.05856558  0.06155084  0.1175722   0.03130978\n",
      "   0.00773021  0.04409422  0.26207891  0.30313998]\n",
      " [ 0.23727271  0.01732496  0.06837526  0.05739778  0.0623436   0.05277745\n",
      "   0.01156101  0.00548202  0.10636169  0.38110352]\n",
      " [ 0.06241697  0.03342842  0.02547604  0.08176492  0.06684788  0.04195476\n",
      "   0.14800604  0.04441819  0.15500379  0.34068292]\n",
      " [ 0.04415782  0.03389535  0.01276841  0.04073615  0.34743673  0.06303912\n",
      "   0.01207844  0.01008473  0.10401301  0.33179039]\n",
      " [ 0.30667236  0.01086829  0.01652901  0.09084239  0.08625484  0.09685218\n",
      "   0.01333926  0.02236717  0.25343904  0.10283545]\n",
      " [ 0.13486043  0.21115981  0.06205487  0.08967986  0.02882141  0.03659461\n",
      "   0.1058125   0.08585427  0.04901472  0.19614759]\n",
      " [ 0.6596911   0.01037285  0.01588672  0.00845813  0.03372696  0.05696997\n",
      "   0.00488832  0.09217189  0.02797218  0.08986193]\n",
      " [ 0.31564143  0.0340024   0.03740803  0.05396073  0.03984109  0.30887845\n",
      "   0.00812224  0.08336999  0.0874514   0.03132424]\n",
      " [ 0.29587856  0.01770776  0.01660424  0.05286971  0.13757907  0.09928437\n",
      "   0.0051118   0.01456298  0.08711763  0.27328384]\n",
      " [ 0.32093257  0.03735489  0.07573021  0.02104211  0.11197852  0.06162595\n",
      "   0.01008284  0.07854265  0.07979387  0.20291635]\n",
      " [ 0.26018023  0.00853568  0.01132426  0.05933581  0.10292675  0.02063387\n",
      "   0.01192673  0.08211128  0.20676391  0.23626149]\n",
      " [ 0.10388782  0.00886825  0.15140848  0.09302625  0.16328004  0.04173562\n",
      "   0.02388573  0.03991525  0.09526464  0.27872792]\n",
      " [ 0.21476127  0.04190649  0.04779358  0.06153966  0.18172893  0.04044159\n",
      "   0.06249517  0.06275094  0.1495702   0.13701211]\n",
      " [ 0.54955959  0.04856115  0.05240644  0.02374115  0.01160953  0.06187394\n",
      "   0.00594082  0.07720187  0.02998081  0.13912466]\n",
      " [ 0.44594088  0.01399862  0.05751322  0.02249127  0.03254538  0.03277722\n",
      "   0.10393551  0.01513292  0.06500977  0.2106552 ]\n",
      " [ 0.43812433  0.0159956   0.04036333  0.05793492  0.0417933   0.02976593\n",
      "   0.00865106  0.03650396  0.07333723  0.25753036]\n",
      " [ 0.26043928  0.03447908  0.02953449  0.03881148  0.03859044  0.16130565\n",
      "   0.0183024   0.17851554  0.05837568  0.18164593]\n",
      " [ 0.18926716  0.1690219   0.04815184  0.06194997  0.08479429  0.23310722\n",
      "   0.10145447  0.03149354  0.04810118  0.03265842]\n",
      " [ 0.66417903  0.00833887  0.07912528  0.01788037  0.01487524  0.08756676\n",
      "   0.02617084  0.04979092  0.03854915  0.01352357]\n",
      " [ 0.33397752  0.0671982   0.0335464   0.05311241  0.08716431  0.115231\n",
      "   0.01298483  0.10116496  0.10952996  0.08609047]\n",
      " [ 0.38437608  0.03954452  0.05372715  0.14005332  0.05855779  0.09593574\n",
      "   0.00965987  0.09024397  0.03736884  0.09053271]\n",
      " [ 0.26735589  0.08600309  0.11938462  0.03625449  0.04649162  0.14378515\n",
      "   0.02168318  0.02595835  0.19181144  0.06127213]\n",
      " [ 0.25169933  0.03199156  0.12914471  0.08734743  0.10479025  0.02308184\n",
      "   0.06705388  0.08465908  0.14100344  0.07922843]\n",
      " [ 0.22372644  0.00745686  0.1758471   0.0213875   0.01279524  0.00717873\n",
      "   0.01969909  0.00879356  0.15339836  0.36971712]\n",
      " [ 0.27113038  0.03896245  0.0081744   0.11590037  0.06250445  0.01214213\n",
      "   0.08850235  0.20487575  0.03004011  0.1677676 ]\n",
      " [ 0.35981894  0.33568123  0.0281975   0.02017769  0.09134915  0.02940774\n",
      "   0.00702862  0.04035106  0.04647197  0.04151605]\n",
      " [ 0.28397423  0.03077881  0.2143984   0.10397509  0.01709575  0.03462454\n",
      "   0.05445559  0.0618396   0.1349698   0.06388824]\n",
      " [ 0.14146297  0.02507127  0.04286864  0.0585907   0.07376448  0.18109019\n",
      "   0.02096561  0.10347786  0.12026399  0.2324442 ]\n",
      " [ 0.12268613  0.04054805  0.00898233  0.306595    0.01365163  0.25936309\n",
      "   0.02880301  0.04717518  0.04900064  0.12319505]\n",
      " [ 0.24668555  0.09443434  0.02483634  0.03285256  0.05778756  0.09895081\n",
      "   0.05286175  0.23310135  0.0922512   0.06623857]\n",
      " [ 0.31614539  0.01512955  0.0346114   0.01675305  0.07761151  0.01992597\n",
      "   0.01447393  0.05543218  0.14395146  0.30596557]\n",
      " [ 0.45453012  0.02831958  0.01508958  0.08853772  0.01310845  0.13948973\n",
      "   0.00532679  0.01646007  0.0750259   0.16411203]\n",
      " [ 0.21362865  0.16037443  0.03000382  0.01532964  0.04268793  0.09351663\n",
      "   0.02755514  0.2897175   0.08130511  0.04588126]]\n",
      "INFO:tensorflow:loss = 2.56141, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1.33303\n",
      "INFO:tensorflow:loss = 0.281206, step = 101 (74.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32675\n",
      "INFO:tensorflow:loss = 0.149962, step = 201 (75.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33406\n",
      "INFO:tensorflow:loss = 0.0946352, step = 301 (74.956 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.33583\n",
      "INFO:tensorflow:loss = 0.116136, step = 401 (74.862 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32521\n",
      "INFO:tensorflow:loss = 0.165437, step = 501 (75.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.31254\n",
      "INFO:tensorflow:loss = 0.0236121, step = 601 (76.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.30547\n",
      "INFO:tensorflow:loss = 0.117606, step = 701 (76.599 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 791 into ./custom_model_dir/1530070694/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 1.24986\n",
      "INFO:tensorflow:loss = 0.0389369, step = 801 (80.008 sec)\n",
      "INFO:tensorflow:global_step/sec: 1.32599\n",
      "INFO:tensorflow:loss = 0.0386783, step = 901 (75.420 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./custom_model_dir/1530070694/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0288875.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fb50d415128>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#训练模型\n",
    "mnist_classifier.train(\n",
    "    input_fn=generate_input_fn(mnist.train, batch_size=BATCH_SIZE),\n",
    "    steps=NUM_STEPS,\n",
    "    hooks=[logging_hook]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（8）测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-06-27-04:00:14\n",
      "INFO:tensorflow:Restoring parameters from ./custom_model_dir/1530070694/model.ckpt-1000\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-27-04:00:35\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9763, global_step = 1000, loss = 1.761\n",
      "{'accuracy': 0.9763, 'loss': 1.7610019, 'global_step': 1000}\n"
     ]
    }
   ],
   "source": [
    "#测试模型并打印结果\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里循环1000次，精度接近98%左右"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（9）保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./custom_model_dir/1530070694/model.ckpt-1000\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'./custom_model_dir/1530070694/1530072109/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    feature_tensor = tf.placeholder(tf.float32, [None, 784])\n",
    "    return tf.estimator.export.ServingInputReceiver({'x': feature_tensor}, {'x': feature_tensor})\n",
    "exported_model_dir = mnist_classifier.export_savedmodel(MODEL_DIR, serving_input_receiver_fn)\n",
    "decoded_model_dir = exported_model_dir.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（10）可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0627 12:02:45.178663 Reloader tf_logging.py:86] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0627 12:02:45.794696 Reloader tf_logging.py:86] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mTensorBoard 0.1.5 at http://master:6006 (Press CTRL+C to quit) ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=$MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.6实例：Keras实现序列式模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第1步：导入需要的库，构造数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIH4X7SgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb50c31cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#构造数据\n",
    "X = np.linspace(-2, 2, 200)\n",
    "np.random.shuffle(X)    # randomize the data\n",
    "#添加一些噪音数据\n",
    "Y = 0.5 * X + 2 + np.random.normal(0, 0.05, (200, ))\n",
    "\n",
    "# 显示输入数据\n",
    "plt.scatter(X, Y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把200份数据划分为训练数据、测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = X[:160], Y[:160]     # first 160 data points\n",
    "X_test, Y_test = X[160:], Y[160:]       # last 40 data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第2步 构造模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建序列实例\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1,activation='relu', input_dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第3步 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选择代价函数及优化器\n",
    "model.compile(loss='mse', optimizer='sgd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第4步 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb50b5ef390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100,verbose=0, batch_size=64,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第5步 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing ------------\n",
      "40/40 [==============================] - 0s 254us/step\n",
      "test cost: 0.0020361226052\n",
      "Weights= [[ 0.50184911]] \n",
      "biases= [ 1.98979783]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print('\\nTesting ------------')\n",
    "cost = model.evaluate(X_test, Y_test, batch_size=40)\n",
    "print('test cost:', cost)\n",
    "W, b = model.layers[0].get_weights()\n",
    "print('Weights=', W, '\\nbiases=', b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可视化结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJVRolfRKTK/H+AKFRhP6JqWAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb509edd7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the prediction\n",
    "Y_pred = model.predict(X_test)\n",
    "plt.scatter(X_test, Y_test)\n",
    "plt.plot(X_test, Y_pred)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.7.1利用TFLearn解决线性回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m0.15967\u001b[0m\u001b[0m | time: 0.005s\n",
      "| SGD | epoch: 1000 | loss: 0.15967 - R2: 0.9692 -- iter: 17/17\n",
      "\n",
      "Regression result:\n",
      "Y = [ 0.28136745]*X + [ 0.58801121]\n",
      "\n",
      "Test prediction for x = 3.2, 3.3, 3.4:\n",
      "[ 1.48838711  1.51652384  1.54466057]\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "\n",
    "# 用于回归预测的数据\n",
    "X = [3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,7.042,10.791,5.313,7.997,5.654,9.27,3.1]\n",
    "Y = [1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,2.827,3.465,1.65,2.904,2.42,2.94,1.3]\n",
    "\n",
    "# 定义线性回归模型\n",
    "input_ = tflearn.input_data(shape=[None])\n",
    "linear = tflearn.single_unit(input_)\n",
    "regression = tflearn.regression(linear, optimizer='sgd', loss='mean_square',\n",
    "                                metric='R2', learning_rate=0.01)\n",
    "m = tflearn.DNN(regression)\n",
    "m.fit(X, Y, n_epoch=1000, show_metric=True, snapshot_epoch=False)\n",
    "\n",
    "print(\"\\nRegression result:\")\n",
    "print(\"Y = \" + str(m.get_weights(linear.W)) +\n",
    "      \"*X + \" + str(m.get_weights(linear.b)))\n",
    "\n",
    "print(\"\\nTest prediction for x = 3.2, 3.3, 3.4:\")\n",
    "print(m.predict([3.2, 3.3, 3.4]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16.7.2利用TFLearn进行深度学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import division, print_function, absolute_import  \n",
    "\n",
    "import tflearn  \n",
    "import tensorflow as tf\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected  \n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d  \n",
    "from tflearn.layers.normalization import local_response_normalization  \n",
    "from tflearn.layers.estimator import regression  \n",
    "#加载mnist数据集（http://yann.lecun.com/exdb/mnist/）  \n",
    "import tflearn.datasets.mnist as mnist  \n",
    "X, Y, testX, testY = mnist.load_data(one_hot=True)  \n",
    "X = X.reshape([-1, 28, 28, 1])  \n",
    "testX = testX.reshape([-1, 28, 28, 1])  \n",
    "\n",
    "tf.reset_default_graph()\n",
    "network = input_data(shape=[None, 28, 28, 1], name='input')  \n",
    "# 定义卷积层\n",
    "network = conv_2d(network, 32, 3, activation='relu', regularizer=\"L2\")  \n",
    "# 定义最大池化层\n",
    "network = max_pool_2d(network, 2)  \n",
    "# 进行归一化处理\n",
    "network = local_response_normalization(network)  \n",
    "network = conv_2d(network, 64, 3, activation='relu', regularizer=\"L2\")  \n",
    "network = max_pool_2d(network, 2)  \n",
    "network = local_response_normalization(network)  \n",
    "# 全连接操作  \n",
    "network = fully_connected(network, 128, activation='tanh')  \n",
    "# dropout操作  \n",
    "network = dropout(network, 0.8)  \n",
    "network = fully_connected(network, 256, activation='tanh')  \n",
    "network = dropout(network, 0.8)  \n",
    "network = fully_connected(network, 10, activation='softmax')  \n",
    "# 回归操作  \n",
    "network = regression(network, optimizer='adam', learning_rate=0.01,  \n",
    "                     loss='categorical_crossentropy', name='target')  \n",
    "\n",
    "# DNN操作，构建深度神经网络,训练模型\n",
    "model = tflearn.DNN(network, tensorboard_verbose=0)  \n",
    "model.fit({'input': X}, {'target': Y}, n_epoch=20,  \n",
    "           validation_set=({'input': testX}, {'target': testY}),  \n",
    "           snapshot_step=100, show_metric=True, run_id='convnet_mnist')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
